{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 课程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 路径规划"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEIJING, CHANGCHUN, MULUMUQI, WUHAN, GUNAGHZOU, SHENZHEN, BANGKOK, SHANGHAI, NEWYORK = \"\"\"\n",
    "BEIJING CHANGCHUN MULUMUQI WUHAN GUANGZHOU SHENZHEN BANGKOK SHANGHAI NEWYORK\n",
    "\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection={\n",
    "    CHANGCHUN:[BEIJING],\n",
    "    BEIJING:[MULUMUQI, CHANGCHUN, WUHAN, SHENZHEN, NEWYORK],\n",
    "    MULUMUQI:[BEIJING],\n",
    "    NEWYORK: [BEIJING, SHANGHAI],\n",
    "    SHANGHAI: [NEWYORK, WUHAN],\n",
    "    WUHAN: [SHANGHAI, BEIJING, GUNAGHZOU],\n",
    "    GUNAGHZOU: [WUHAN, BANGKOK],\n",
    "    SHENZHEN: [WUHAN, BANGKOK],\n",
    "    BANGKOK: [SHENZHEN, GUNAGHZOU]\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=nx.Graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:611: MatplotlibDeprecationWarning: isinstance(..., numbers.Number)\n",
      "  if cb.is_numlike(alpha):\n"
     ]
    }
   ],
   "source": [
    "nx.draw(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NAV(st,des,map):\n",
    "    Queue=[[st]]     # FIFO \n",
    "    \n",
    "    while (Queue) :\n",
    "        path=Queue.pop(0) # pathes poped element defined as a list  \n",
    "        node=path[-1] # last element choice .list index by [] \n",
    "        successor=map[node] # subnode from node\n",
    "        \n",
    "        for e in successor:\n",
    "            if(e==des):\n",
    "                path.append(e)\n",
    "                return path\n",
    "            else:\n",
    "                Queue.append(path+[e])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_route(routes):\n",
    "    print('✈->'.join(routes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGCHUN✈->BEIJING✈->SHENZHEN\n"
     ]
    }
   ],
   "source": [
    "draw_route(NAV(CHANGCHUN, SHENZHEN, connection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 语句自动生成\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "增加“=”号运算符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimal_grammar = \"\"\"\n",
    "expression => operator op operator equal operator  \n",
    "operator => num\n",
    "num => 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | num num\n",
    "op => + | - | * | /\n",
    "equal => =\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = \"\"\"\n",
    "sentence => noun_phrase verb_phrase \n",
    "noun_phrase => Article Adj* noun\n",
    "Adj* => null | Adj Adj*\n",
    "verb_phrase => verb noun_phrase\n",
    "Article =>  一个 | 这个\n",
    "noun =>   女人 |  篮球 | 桌子 | 小猫\n",
    "verb => 看着   |  坐在 |  听着 | 看见\n",
    "Adj =>   蓝色的 |  好看的 | 小小的\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_grammar(grammar_str,sep='=>'):\n",
    "    grammar = {} #定义字典\n",
    "    for line in grammar_str.split('\\n'):\n",
    "        line = line.strip()  #移除空格隔开的字符\n",
    "        if not line: continue\n",
    "            \n",
    "        target,rule = line.split(sep) \n",
    "        \n",
    "        grammar[target.strip()]=[r.split() for r in rule.split('|')] \n",
    "    return grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene(grammar_parsed,target='sentence'):\n",
    "    if target not in grammar_parsed: return target\n",
    "    rules = random.choice(grammar_parsed[target])\n",
    "    return '' .join(gene(grammar_parsed,target=r) for r in rules if r!='null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=parse_grammar(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这个蓝色的好看的小猫看着一个蓝色的好看的篮球\n"
     ]
    }
   ],
   "source": [
    "print (gene(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "artim=parse_grammar(decimal_grammar,sep='=>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3+2=7\n"
     ]
    }
   ],
   "source": [
    "print (gene(artim,target='expression'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题1：第一个人机对话程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import jieba\n",
    "import re\n",
    "from fnmatch import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_responses = {\n",
    "    '?*x hello ?*y': ['How do you do', 'Please state your problem'],\n",
    "    '?*x I want ?*y': ['what would it mean if you got ?y', 'Why do you want ?y', 'Suppose you got ?y soon'],\n",
    "    '?*x if ?*y': ['Do you really think its likely that ?y', 'Do you wish that ?y', 'What do you think about ?y', 'Really-- if ?y'],\n",
    "    '?*x no ?*y': ['why not?', 'You are being a negative', 'Are you saying \\'No\\' just to be negative?'],\n",
    "    '?*x I was ?*y': ['Were you really', 'Perhaps I already knew you were ?y', 'Why do you tell me you were ?y now?'],\n",
    "    '?*x I feel ?*y': ['Do you often feel ?y ?', 'What other feelings do you have?'],\n",
    "    '?*x你好?*y': ['你好呀', '请告诉我你的问题'],\n",
    "    '?*x我想?*y': ['你觉得?y有什么意义呢？', '为什么你想?y', '你可以想想你很快就可以?y了'],\n",
    "    '?*x我想要?*y': ['?x想问你，你觉得?y有什么意义呢?', '为什么你想?y', '?x觉得... 你可以想想你很快就可以有?y了', '你看?x像?y不', '我看你就像?y'],\n",
    "    '?*x喜欢?*y': ['喜欢?y的哪里？', '?y有什么好的呢？', '你想要?y吗？'],\n",
    "    '?*x讨厌?*y': ['?y怎么会那么讨厌呢?', '讨厌?y的哪里？', '?y有什么不好呢？', '你不想要?y吗？'],\n",
    "    '?*xAI?*y': ['你为什么要提AI的事情？', '你为什么觉得AI要解决你的问题？'],\n",
    "    '?*x机器人?*y': ['你为什么要提机器人的事情？', '你为什么觉得机器人要解决你的问题？'],\n",
    "    '?*x对不起?*y': ['不用道歉', '你为什么觉得你需要道歉呢?'],\n",
    "    '?*x我记得?*y': ['你经常会想起这个吗？', '除了?y你还会想起什么吗？', '你为什么和我提起?y'],\n",
    "    '?*x如果?*y': ['你真的觉得?y会发生吗？', '你希望?y吗?', '真的吗？如果?y的话', '关于?y你怎么想？'],\n",
    "    '?*x我?*z梦见?*y':['真的吗? --- ?y', '你在醒着的时候，以前想象过?y吗？', '你以前梦见过?y吗'],\n",
    "    '?*x妈妈?*y': ['你家里除了?y还有谁?', '嗯嗯，多说一点和你家里有关系的', '她对你影响很大吗？'],\n",
    "    '?*x爸爸?*y': ['你家里除了?y还有谁?', '嗯嗯，多说一点和你家里有关系的', '他对你影响很大吗？', '每当你想起你爸爸的时候， 你还会想起其他的吗?'],\n",
    "    '?*x我愿意?*y': ['我可以帮你?y吗？', '你可以解释一下，为什么想?y'],\n",
    "    '?*x我很难过，因为?*y': ['我听到你这么说， 也很难过', '?y不应该让你这么难过的'],\n",
    "    '?*x难过?*y': ['我听到你这么说， 也很难过',\n",
    "                 '不应该让你这么难过的，你觉得你拥有什么，就会不难过?',\n",
    "                 '你觉得事情变成什么样，你就不难过了?'],\n",
    "    '?*x就像?*y': ['你觉得?x和?y有什么相似性？', '?x和?y真的有关系吗？', '怎么说？'],\n",
    "    '?*x和?*y都?*z': ['你觉得?z有什么问题吗?', '?z会对你有什么影响呢?'],\n",
    "    '?*x和?*y一样?*z': ['你觉得?z有什么问题吗?', '?z会对你有什么影响呢?'],\n",
    "    '?*x我是?*y': ['真的吗？', '?x想告诉你，或许我早就知道你是?y', '你为什么现在才告诉我你是?y'],\n",
    "    '?*x我是?*y吗': ['如果你是?y会怎么样呢？', '你觉得你是?y吗', '如果你是?y，那一位着什么?'],\n",
    "    '?*x你是?*y吗':  ['你为什么会对我是不是?y感兴趣?', '那你希望我是?y吗', '你要是喜欢， 我就会是?y'],\n",
    "    '?*x你是?*y' : ['为什么你觉得我是?y'],\n",
    "    '?*x因为?*y' : ['?y是真正的原因吗？', '你觉得会有其他原因吗?'],\n",
    "    '?*x我不能?*y': ['你或许现在就能?y', '如果你能?y,会怎样呢？'],\n",
    "    '?*x我觉得?*y': ['你经常这样感觉吗？', '除了到这个，你还有什么其他的感觉吗？'],\n",
    "    '?*x我?*y你?*z': ['其实很有可能我们互相?y'],\n",
    "    '?*x你为什么不?*y': ['你自己为什么不?y', '你觉得我不会?y', '等我心情好了，我就?y'],\n",
    "    '?*x好的?*y': ['好的', '你是一个很正能量的人'],\n",
    "    '?*x嗯嗯?*y': ['好的', '你是一个很正能量的人'],\n",
    "    '?*x不嘛?*y': ['为什么不？', '你有一点负能量', '你说 不，是想表达不想的意思吗？'],\n",
    "    '?*x不要?*y': ['为什么不？', '你有一点负能量', '你说 不，是想表达不想的意思吗？'],\n",
    "    '?*x有些人?*y': ['具体是哪些人呢?'],\n",
    "    '?*x有的人?*y': ['具体是哪些人呢?'],\n",
    "    '?*x某些人?*y': ['具体是哪些人呢?'],\n",
    "    '?*x每个人?*y': ['我确定不是人人都是', '你能想到一点特殊情况吗？', '例如谁？', '你看到的其实只是一小部分人'],\n",
    "    '?*x所有人?*y': ['我确定不是人人都是', '你能想到一点特殊情况吗？', '例如谁？', '你看到的其实只是一小部分人'],\n",
    "    '?*x总是?*y': ['你能想到一些其他情况吗?', '例如什么时候?', '你具体是说哪一次？', '真的---总是吗？'],\n",
    "    '?*x一直?*y': ['你能想到一些其他情况吗?', '例如什么时候?', '你具体是说哪一次？', '真的---总是吗？'],\n",
    "    '?*x或许?*y': ['你看起来不太确定'],\n",
    "    '?*x可能?*y': ['你看起来不太确定'],\n",
    "    '?*x他们是?*y吗？': ['你觉得他们可能不是?y？'],\n",
    "    '?*x': ['很有趣', '请继续', '我不太确定我很理解你说的, 能稍微详细解释一下吗?']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_variable(pat):\n",
    "    return pat.startswith('?') and all(s.isalpha() for s in pat[1:]) # all() 判定所有元素是否均为true  isalpha()判定是否为字母字符且不留空"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pattern_segment(pattern):\n",
    "    return pattern.startswith('?*') and all(a.isalpha() for a in pattern[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ruleskey(speech,patten):\n",
    "\n",
    "    string=re.sub(r'\\?\\*.','*',patten)\n",
    "    string=string.strip()\n",
    "    if(string.startswith('*')):\n",
    "        string=string.replace(' ','',1)\n",
    "    if(string.endswith('*')):\n",
    "        pos=string.rfind(' ')\n",
    "        string=string[:pos]+string[pos:].replace(' ','',1)\n",
    "    return fnmatch(speech,string)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsitite(rule, parsed_rules): \n",
    "    if not rule: return [] \n",
    "    return [parsed_rules.get(rule[0], rule[0])] + subsitite(rule[1:], parsed_rules) #便历rule列表,如果字典有匹配项，则替换，没有则返回当前值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pat_to_dict(patterns):\n",
    "    return {k: ' '.join(v) if isinstance(v, list) else v for k, v in patterns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_match(pattern, saying):\n",
    "    seg_pat, rest = pattern[0], pattern[1:]\n",
    "    seg_pat = seg_pat.replace('?*', '?')\n",
    "    \n",
    "    if not rest: return (seg_pat, saying), len(saying)    \n",
    "    \n",
    "    for i, token in enumerate(saying):\n",
    "        if rest[0] == token:  \n",
    "            return (seg_pat, saying[:i]), i\n",
    "    \n",
    "    return (seg_pat, saying), len(saying)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail = [True, None]\n",
    "\n",
    "def pat_match_with_seg(pattern, saying):\n",
    "    if not pattern or not saying: return []\n",
    "    \n",
    "    pat = pattern[0]\n",
    "    \n",
    "    if is_variable(pat):\n",
    "        return [(pat, saying[0])] + pat_match_with_seg(pattern[1:], saying[1:])\n",
    "    elif is_pattern_segment(pat):\n",
    "        match, index = segment_match(pattern, saying)\n",
    "        return [match] + pat_match_with_seg(pattern[1:], saying[index:])\n",
    "    elif pat == saying[0]:\n",
    "        return pat_match_with_seg(pattern[1:], saying[1:])\n",
    "    else:\n",
    "        return fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(saying, rules=rule_responses):\n",
    "    got_pattern=[]    \n",
    "    for pat_key in rules.keys():\n",
    "         if map_ruleskey(saying,pat_key):\n",
    "            got_pattern=pat_match_with_seg(pat_key.split(),saying.split())\n",
    "            break\n",
    "#    print(got_pattern)\n",
    "    rule_response=random.choice(rules[pat_key])\n",
    "    \n",
    "    return ' '.join(subsitite(rule_response.split(), pat_to_dict(got_pattern)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Please state your problem'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Do you often feel nervous ?'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(\"I feel nervous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why do you want that shoes'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(\"I want that shoes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题2：中文对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pat(patten):\n",
    "\n",
    "    seg_list = jieba.cut(patten, cut_all=False)\n",
    "    \n",
    "    string=list(seg_list)  #'*?x我?*z梦见?*y'\n",
    "\n",
    "    strlist=[]\n",
    "    s=''\n",
    "\n",
    "    for e in string:\n",
    "        if not '\\u4e00'<=e<='\\u9fa5' : #判断e 是否为中文\n",
    "            s=s+e \n",
    "            continue;\n",
    "        if s :\n",
    "            strlist.append(s)\n",
    "            s=''\n",
    "        strlist.append(e) \n",
    "    if s :\n",
    "        strlist.append(s)\n",
    "        \n",
    "    return  strlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_match_cn(pattern, saying):\n",
    "    seg_pat, rest = pattern[0], pattern[1:]\n",
    "    seg_pat = seg_pat.replace('?*', '?')\n",
    "    \n",
    "    if not rest: return (seg_pat, saying), len(saying)    \n",
    "    \n",
    "    for i, token in enumerate(saying):\n",
    "        if rest[0] == token:  \n",
    "            return (seg_pat, saying[:i]), i\n",
    "    \n",
    "    return (seg_pat, saying), len(saying)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail = [True, None]\n",
    "\n",
    "def pat_match_with_seg_cn(pattern, saying):\n",
    "    if not pattern or not saying: return []  \n",
    "    pat = pattern[0]    \n",
    "    if pat.startswith('?*'):\n",
    "        match, index = segment_match_cn(pattern, saying)\n",
    "#        print (match,index)\n",
    "        return [match] + pat_match_with_seg_cn(pattern[1:], saying[index:])\n",
    "    elif pat == saying[0]:\n",
    "        return pat_match_with_seg_cn(pattern[1:], saying[1:])\n",
    "    else:\n",
    "        return fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ruleskey_cn(speech,patten):\n",
    "\n",
    "    string=re.sub(r'\\?\\*.','*',patten)\n",
    "    string=string.strip()\n",
    " #   if(string.startswith('*')):\n",
    " #       string=string.replace(' ','',1)\n",
    " #   if(string.endswith('*')):\n",
    " #       pos=string.rfind(' ')\n",
    " #       string=string[:pos]+string[pos:].replace(' ','',1)\n",
    "    return fnmatch(speech,string)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_cn(saying, rules=rule_responses):\n",
    "    got_pattern=[]    \n",
    "    instrunction=list(jieba.cut(saying))\n",
    "    for pat_key in rules.keys():\n",
    "         if map_ruleskey_cn(saying,pat_key):\n",
    "            patten=list(jieba.cut(pat_key))\n",
    "            got_pattern=pat_match_with_seg_cn(parse_pat(pat_key),instrunction)\n",
    "            break\n",
    "#    print (got_pattern)\n",
    "    rule_response=random.choice(rules[pat_key])\n",
    "    return ''.join(subsitite(parse_pat(rule_response), pat_to_dict(got_pattern)))\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\DELL\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.681 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'我听到你这么说， 也很难过'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response_cn('我很难过')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你觉得我不会踢足球'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response_cn('你为什么不踢足球')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好呀'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response_cn('AI你好')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你以前梦见过大海吗'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response_cn('昨晚我梦见大海')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题3：更好玩的人机对话"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "中文对话基础上添加数字运算：\n",
    "例如：“2只猫加3只猫等于多少”=》“答案是 5”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_mix = {\n",
    "    '?*m ?*op ?*n 等于 ?*z': ['答案是 ?m ?n ?op'],\n",
    "    '?*m ?*op ?*n 一共 ?*z': ['答案是 ?m ?n ?op']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "opr={'加':'+','减':'-'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pat(patten):\n",
    "\n",
    "    seg_list = jieba.cut(patten, cut_all=False)\n",
    "    \n",
    "    string=list(seg_list)  \n",
    "\n",
    "    strlist=[]\n",
    "    s=''\n",
    "\n",
    "    for e in string:\n",
    "        if  not '\\u4e00'<=e<='\\u9fa5' and not e==' ' : #e 不是中文 且 e不为空格\n",
    "            s=s+e \n",
    "            continue;\n",
    "        if s :\n",
    "            strlist.append(s)\n",
    "            s=''\n",
    "        strlist.append(e) \n",
    "    if s :\n",
    "        strlist.append(s)\n",
    "    for i in strlist :   #删除列表中所有空格' '\n",
    "        if ' ' in strlist:\n",
    "            strlist.remove(' ')\n",
    "            \n",
    "    return  strlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_match_mix(pattern, saying, mode):\n",
    "    seg_pat, rest = pattern[0], pattern[1:]\n",
    "    seg_pat = seg_pat.replace('?*', '?')\n",
    "    if not rest: return (seg_pat, saying), len(saying)    \n",
    "    \n",
    "    for i, token in enumerate(saying):\n",
    "        if mode=='numeric':\n",
    "            if token.isnumeric():\n",
    "                return (seg_pat, saying[i]),  i\n",
    "        elif mode== 'operation': \n",
    "            if token=='加' or token=='减':\n",
    "                symbol=opr[token]\n",
    "                return (seg_pat, symbol), i\n",
    "        else :\n",
    "            if rest[0] == token:  \n",
    "                return (seg_pat, saying[:i]), i\n",
    "   \n",
    "    return (seg_pat, saying), len(saying)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail = [True, None]\n",
    "\n",
    "def pat_match_with_seg_num(pattern, saying):\n",
    "    if not pattern or not saying: return []  \n",
    "    pat = pattern[0]    \n",
    "    if pat=='?*n'or pat=='?*m'  :\n",
    "        match, index = segment_match_mix(pattern, saying,'numeric')\n",
    "        return [match] + pat_match_with_seg_num(pattern[1:], saying[index:])\n",
    "    if pat=='?*op':\n",
    "        match, index = segment_match_mix(pattern, saying,'operation')\n",
    "        return [match] + pat_match_with_seg_num(pattern[1:], saying[index:])\n",
    "    if pat=='?*x' or pat=='?*y' or pat=='?*z'  :\n",
    "        match, index = segment_match_mix(pattern, saying,'textual')\n",
    "        return [match] + pat_match_with_seg_num(pattern[1:], saying[index:])\n",
    "    if pat == saying[0]:\n",
    "        return pat_match_with_seg_num(pattern[1:], saying[1:])\n",
    "    else:\n",
    "        return pat_match_with_seg_num(pattern, saying[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ruleskey_num(speech,patten):\n",
    "\n",
    "    string=re.sub(r'\\?\\*[^o]','*',patten)\n",
    "    string=re.sub(r'\\?\\*[o][p]','[\\u52a0|\\u51cf]',string)\n",
    "    string=re.sub(' ','',string)\n",
    " \n",
    "    return fnmatch(speech,string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=[]\n",
    "\n",
    "def subsitite_mix(rule, parsed_rules): \n",
    "    if not rule: return []\n",
    " \n",
    "    g=parsed_rules.get(rule[0],rule[0])\n",
    "    \n",
    "    if rule[0]=='?m' or rule[0]=='?n':\n",
    "        t.append(int(g))\n",
    "        return subsitite_mix(rule[1:], parsed_rules)\n",
    "    if rule[0]=='?op':\n",
    "        if g=='+': \n",
    "            g=str(t.pop()+t.pop())\n",
    "        if g=='-':\n",
    "            g=str(-t.pop()+t.pop())\n",
    "    return [g] + subsitite_mix(rule[1:], parsed_rules) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#subsitite_mix(parse_pat('答案是 ?m ?n ?op'),pat_to_dict([('?m', '5'), ('?op', '-'), ('?n', '3'), ('?z', ['几只'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_mix(saying, rules=rule_mix):\n",
    "    got_pattern=[]    \n",
    "    instruction=list(jieba.cut(saying,cut_all=True))\n",
    "#    print (instruction)\n",
    "    for pat_key in rules.keys():\n",
    "        if map_ruleskey_num(saying,pat_key):\n",
    "\n",
    "            got_pattern=pat_match_with_seg_num(parse_pat(pat_key),instruction)\n",
    "            break\n",
    "#    print (got_pattern)\n",
    "\n",
    "    return ''.join(subsitite_mix(parse_pat(rules[pat_key][0]), pat_to_dict(got_pattern)))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'答案是2'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response_mix('5只猫减3只猫一共几只猫?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'答案是19'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response_mix('16只猫加3只猫等于几只猫?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题 4 ：关于以上程序的思考"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.这样的程序有什么优点？有什么缺点？你有什么可以改进的方法吗？ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的程序实现较为简单，能够实现基本的应答。但有几个主要问题：\n",
    "1.字典匹配Key语句表达式是固定的，如果saying语句关键字或者顺序不对应，则无法应答及匹配。后续可采用形式化语言的方式进行匹配。\n",
    "2.目前设计的对话缺少连续性，后续应通过能在对话基础上标注关键信息，在机器回答语句后面添加下一步应该获取应答的链接从而实现人机连续对话。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.什么是数据驱动？数据驱动在这个程序里如何体现？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据驱动是根据输入的数据对其进行组织形成信息，之后对相关的信息进行整合和提炼，在数据的基础上经过训练和拟合形成自动化的决策的过程。本程序中即利用字典匹配输入并提取关键字，再对关键字封装后进行输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.数据驱动与 AI 的关系是什么？ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "数据驱动是面向场景进行软件或系统设计的一种设计方法，而AI是数据加工提炼的工具。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
